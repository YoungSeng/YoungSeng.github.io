---
title: "GTN-Bailando: Genre Consistent Long-Term 3D Dance Generation based on Pre-trained Genre Token Network"
collection: publications
permalink: /publication/2023-04-25
date: 2023-04-25
venue: 'ICASSP'
citation: 'Haolin Zhuang, Shun Lei, Long Xiao, Weiqin Li, Liyang Chen, <b>Sicheng Yang</b>, Zhiyong Wu, Shiyin Kang, Helen Meng. (2023). &quot;GTN-Bailando: Genre Consistent Long-Term 3D Dance Generation based on Pre-trained Genre Token Network.&quot; <i>ICASSP</i>, 1-5, doi: 10.1109/ICASSP49357.2023.10095203.'
---



<!-- Recommended citation: Your Name, You. (2009). "Paper Title Number 1." <i>Journal 1</i>. 1(1). -->


Music-driven 3D dance generation has become an intensive research topic in recent years with great potential for real-world applications. Most existing methods lack the consideration of genre, which results in genre inconsistency in the generated dance movements. In addition, the correlation between the dance genre and the music has not been investigated. To address these issues, we propose a genre-consistent dance generation framework, GTN-Bailando. First, we propose the Genre Token Network (GTN), which infers the genre from music to enhance the genre consistency of long-term dance generation. Second, to improve the generalization capability of the model, the strategy of pre-training and fine-tuning is adopted.Experimental results on the AIST++ dataset show that the proposed dance generation framework outperforms state-of-the-art methods in terms of motion quality and genre consistency.

[Browse paper here](/files/2304.12704.pdf)
